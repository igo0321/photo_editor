import streamlit as st
from PIL import Image, ImageOps
import mediapipe as mp
import numpy as np
import io
import zipfile
import os
from pdf2image import convert_from_bytes

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(layout="wide", page_title="Profile Photo Cropper")

# --- å®šæ•° ---
mp_face_detection = mp.solutions.face_detection
face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)

# --- é–¢æ•°å®šç¾© ---

def load_image(uploaded_file):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿PIL Imageã«å¤‰æ›"""
    try:
        if uploaded_file.type == "application/pdf":
            # ä¿®æ­£: DPIã‚’200 -> 300ã«å¤‰æ›´ã—ã¦ç”»è³ªå‘ä¸Šï¼ˆé¡”èªè­˜ç²¾åº¦ã®æ”¹å–„ï¼‰
            # 300dpiã‚ã‚Œã°A4ã‚µã‚¤ã‚ºã§ã‚‚é¡”ã®è¼ªéƒ­ãŒãã£ãã‚Šã—ã€éå‰°ãªã‚ºãƒ¼ãƒ ã‚’é˜²ã’ã¾ã™
            images = convert_from_bytes(uploaded_file.getvalue(), dpi=300, fmt='jpeg')
            return images[0] if images else None
        else:
            image = Image.open(uploaded_file)
            image = ImageOps.exif_transpose(image) # å›è»¢è£œæ­£
            return image
    except Exception as e:
        st.error(f"Error loading {uploaded_file.name}: {e}")
        return None

def analyze_face_coordinates(image):
    """ç”»åƒã‹ã‚‰é¡”ã¨ç›®ã®åº§æ¨™(ç›¸å¯¾å€¤ 0.0-1.0)ã‚’æŠ½å‡º"""
    img_np = np.array(image.convert('RGB'))
    results = face_detection.process(img_np)
    
    if not results.detections:
        return None

    detection = results.detections[0]
    bbox = detection.location_data.relative_bounding_box
    kps = detection.location_data.relative_keypoints
    
    # ç›®ã®ä¸­å¿ƒä½ç½®
    right_eye = kps[0]
    left_eye = kps[1]
    eye_center_x = (right_eye.x + left_eye.x) / 2
    eye_center_y = (right_eye.y + left_eye.y) / 2
    
    return {
        'face_h': bbox.height,
        'face_cx': bbox.xmin + bbox.width / 2,
        'face_cy': bbox.ymin + bbox.height / 2,
        'eye_cy': eye_center_y
    }

def create_smart_cropped_image(original_img, face_data, target_w, target_h, face_ratio, eye_level, bg_mode):
    """
    è¦ä»¶ã«åŸºã¥ããƒªã‚µã‚¤ã‚ºãƒ»åˆ‡ã‚ŠæŠœããƒ»ä½™ç™½å‡¦ç†ã‚’è¡Œã£ãŸç”»åƒã‚’ç”Ÿæˆã—ã¦è¿”ã™
    å„ªå…ˆé †ä½:
    1. æŒ‡å®šã®é¡”ã‚µã‚¤ã‚ºãƒ»ç›®ç·šä½ç½®ã§è¨ˆç®—
    2. ç”»åƒã‹ã‚‰ã¯ã¿å‡ºã‚‹å ´åˆã€ä½ç½®èª¿æ•´(Shift)ã¨æ‹¡å¤§(Zoom 15%ä»¥å†…)ã§ã¯ã¿å‡ºã—ã‚’è§£æ¶ˆãƒˆãƒ©ã‚¤
    3. ãã‚Œã§ã‚‚ç„¡ç†ãªã‚‰æŒ‡å®šèƒŒæ™¯(ç™½/é»’)ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    """
    img_w, img_h = original_img.size
    
    # --- 1. ç†æƒ³ã®åˆ‡ã‚ŠæŠœãæ ã‚’è¨ˆç®— ---
    if face_data:
        # é¡”ã®é«˜ã•(px) / è¨­å®šæ¯”ç‡ = åˆ‡ã‚ŠæŠœãæ ã®é«˜ã•
        face_h_px = face_data['face_h'] * img_h
        crop_h = face_h_px / face_ratio
        
        # ç›®ã®ä½ç½®åˆã‚ã›
        eye_y_px = face_data['eye_cy'] * img_h
        # æ ã®ä¸Šè¾º(top) = ç›®ã®Yåº§æ¨™ - (æ ã®é«˜ã• * ç›®ç·šã®è¨­å®š%)
        crop_top = eye_y_px - (crop_h * eye_level)
        crop_cy = crop_top + (crop_h / 2)
        
        # æ¨ªä½ç½®ã¯é¡”ä¸­å¿ƒ
        crop_cx = face_data['face_cx'] * img_w
    else:
        # é¡”ãŒãªã„å ´åˆã¯ç”»åƒä¸­å¿ƒ
        crop_h = img_h * 0.8
        crop_cx, crop_cy = img_w / 2, img_h / 2

    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‹ã‚‰å¹…ã‚’è¨ˆç®—
    target_aspect = target_w / target_h
    crop_w = crop_h * target_aspect
    
    # ç†æƒ³ã®åº§æ¨™ (x1, y1, x2, y2)
    x1 = crop_cx - crop_w / 2
    y1 = crop_cy - crop_h / 2
    x2 = crop_cx + crop_w / 2
    y2 = crop_cy + crop_h / 2
    
    # --- 2. 15%ãƒ«ãƒ¼ãƒ«ã«ã‚ˆã‚‹è‡ªå‹•èª¿æ•´ (Shift & Zoom) ---
    
    # ç¾åœ¨ã®æ ãŒç”»åƒå†…ã«åã¾ã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    # ã¯ã¿å‡ºã—é‡(æ­£ã®å€¤ãªã‚‰ã¯ã¿å‡ºã—ã¦ã„ã‚‹)
    overflow_left = max(0, -x1)
    overflow_right = max(0, x2 - img_w)
    overflow_top = max(0, -y1)
    overflow_bottom = max(0, y2 - img_h)
    
    has_overflow = (overflow_left + overflow_right + overflow_top + overflow_bottom) > 0
    
    # æœ€çµ‚çš„ãªåˆ‡ã‚ŠæŠœããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    final_x1, final_y1, final_x2, final_y2 = x1, y1, x2, y2
    needs_padding = False
    
    if has_overflow:
        # A. ã¾ãšä½ç½®ãšã‚‰ã—(Shift)ã§è§£æ±ºã§ãã‚‹ã‹ï¼Ÿ
        # å¹…ãŒç”»åƒã‚ˆã‚Šå°ã•ã„ãªã‚‰ã€å·¦å³ã«å‹•ã‹ã—ã¦åã‚ã‚‹
        if crop_w <= img_w:
            if final_x1 < 0: # å·¦ã«ã¯ã¿å‡ºã—ã¦ã‚‹ -> å³ã«ãšã‚‰ã™
                offset = -final_x1
                final_x1 += offset
                final_x2 += offset
            elif final_x2 > img_w: # å³ã«ã¯ã¿å‡ºã—ã¦ã‚‹ -> å·¦ã«ãšã‚‰ã™
                offset = final_x2 - img_w
                final_x1 -= offset
                final_x2 -= offset
        
        # é«˜ã•ãŒç”»åƒã‚ˆã‚Šå°ã•ã„ãªã‚‰ã€ä¸Šä¸‹ã«å‹•ã‹ã—ã¦åã‚ã‚‹
        if crop_h <= img_h:
            if final_y1 < 0:
                offset = -final_y1
                final_y1 += offset
                final_y2 += offset
            elif final_y2 > img_h:
                offset = final_y2 - img_h
                final_y1 -= offset
                final_y2 -= offset

        # ãšã‚‰ã—ãŸå¾Œã€ã¾ã ã¯ã¿å‡ºã—ã¦ã„ã‚‹ã‹å†ãƒã‚§ãƒƒã‚¯ (ç”»åƒã‚µã‚¤ã‚ºè‡ªä½“ãŒè¶³ã‚Šãªã„å ´åˆãªã©)
        overflow_w = max(0, -final_x1) + max(0, final_x2 - img_w)
        overflow_h = max(0, -final_y1) + max(0, final_y2 - img_h)
        
        if overflow_w > 0 or overflow_h > 0:
            # B. ã‚ºãƒ¼ãƒ (æ ã‚’ç¸®å°)ã—ã¦è§£æ±ºã§ãã‚‹ã‹ï¼Ÿ (15%ãƒ«ãƒ¼ãƒ«)
            # ç¾åœ¨ã®æ ã‚µã‚¤ã‚ºã«å¯¾ã—ã¦ã€ç”»åƒå†…ã«åã‚ã‚‹ãŸã‚ã«å¿…è¦ãªç¸®å°ç‡ã‚’è¨ˆç®—
            # width_scale: ç”»åƒå¹… / ç¾åœ¨ã®æ å¹… (ã“ã‚ŒãŒ1.0ä»¥ä¸‹ãªã‚‰ç¸®å°å¿…è¦)
            scale_w = img_w / crop_w if crop_w > img_w else 1.0
            scale_h = img_h / crop_h if crop_h > img_h else 1.0
            
            min_scale = min(scale_w, scale_h)
            
            # è¨±å®¹ç¯„å›²: ã€Œ15%ã®æ‹¡å¤§ã€= æ ã‚’ 1 / 1.15 å€ (ç´„0.87) ã¾ã§å°ã•ãã—ã¦ã„ã„
            ALLOWED_SHRINK_LIMIT = 1.0 / 1.15
            
            if min_scale >= ALLOWED_SHRINK_LIMIT:
                # è¨±å®¹ç¯„å›²å†…ãªã®ã§ã€æ ã‚’ç¸®å°(Zoom In)ã—ã¦ãƒ•ã‚£ãƒƒãƒˆã•ã›ã‚‹
                new_crop_w = crop_w * min_scale
                new_crop_h = crop_h * min_scale
                
                # ä¸­å¿ƒã‚’ç¶­æŒã—ã¤ã¤ãƒªã‚µã‚¤ã‚º
                center_x = (final_x1 + final_x2) / 2
                center_y = (final_y1 + final_y2) / 2
                
                # ç”»åƒå¤–ã«ã¯ã¿å‡ºã•ãªã„ã‚ˆã†ä¸­å¿ƒã‚‚å†ã‚¯ãƒ©ãƒ³ãƒ—
                center_x = max(new_crop_w/2, min(img_w - new_crop_w/2, center_x))
                center_y = max(new_crop_h/2, min(img_h - new_crop_h/2, center_y))
                
                final_x1 = center_x - new_crop_w / 2
                final_y1 = center_y - new_crop_h / 2
                final_x2 = center_x + new_crop_w / 2
                final_y2 = center_y + new_crop_h / 2
                
                # ã“ã‚Œã§Paddingä¸è¦
                needs_padding = False
            else:
                # 15%ã‚’è¶…ãˆã¦ã—ã¾ã† -> ã‚ãã‚‰ã‚ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°(èƒŒæ™¯è¿½åŠ )ã™ã‚‹
                # ãŸã ã—ã€ã§ãã‚‹ã ã‘ç”»åƒã‚’å…¥ã‚Œã‚‹ãŸã‚ã«ã€æ ã¯ç†æƒ³ã‚µã‚¤ã‚ºã®ã¾ã¾ã«ã™ã‚‹
                # (ä¸Šã§è¨ˆç®—ã—ãŸIdeal Boxã‚’ä½¿ã†)
                final_x1, final_y1, final_x2, final_y2 = x1, y1, x2, y2
                needs_padding = True
    
    # --- 3. ç”»åƒç”Ÿæˆå®Ÿè¡Œ ---
    
    if not needs_padding:
        # é€šå¸¸ã®åˆ‡ã‚ŠæŠœã & ãƒªã‚µã‚¤ã‚º
        box = (final_x1, final_y1, final_x2, final_y2)
        # åº§æ¨™ã‚’ç”»åƒå†…ã«åã‚ã‚‹(å¿µã®ãŸã‚)
        cx1 = max(0, box[0])
        cy1 = max(0, box[1])
        cx2 = min(img_w, box[2])
        cy2 = min(img_h, box[3])
        
        cropped = original_img.crop((cx1, cy1, cx2, cy2))
        return cropped.resize((target_w, target_h), Image.Resampling.LANCZOS)
    
    else:
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†
        # èƒŒæ™¯è‰²æ±ºå®š
        bg_color = (255, 255, 255) if bg_mode == "ç™½" else (0, 0, 0)
        
        # 1. å…ƒç”»åƒã‚’ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ç¶­æŒã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ å†…ã«åã¾ã‚‹æœ€å¤§ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
        #    ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚ºã¨å…ƒç”»åƒã®æ¯”ç‡ã‚’æ¯”è¼ƒ
        src_aspect = img_w / img_h
        
        if src_aspect > target_aspect:
            # å…ƒç”»åƒã®æ–¹ãŒæ¨ªé•· -> å¹…ã‚’åˆã‚ã›ã‚‹
            resize_w = target_w
            resize_h = int(target_w / src_aspect)
        else:
            # å…ƒç”»åƒã®æ–¹ãŒç¸¦é•· -> é«˜ã•ã‚’åˆã‚ã›ã‚‹
            resize_h = target_h
            resize_w = int(target_h * src_aspect)
            
        resized_src = original_img.resize((resize_w, resize_h), Image.Resampling.LANCZOS)
        
        # 2. ãƒ™ãƒ¼ã‚¹ä½œæˆ
        new_img = Image.new("RGB", (target_w, target_h), bg_color)
        
        # 3. ä¸­å¤®é…ç½®
        paste_x = (target_w - resize_w) // 2
        paste_y = (target_h - resize_h) // 2
        
        new_img.paste(resized_src, (paste_x, paste_y))
        return new_img

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
if 'images_data' not in st.session_state:
    st.session_state['images_data'] = {} 

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.title("è¨­å®š")

# 1. å‡ºåŠ›ã‚µã‚¤ã‚º
st.sidebar.subheader("â‘  å‡ºåŠ›ã‚µã‚¤ã‚º")
col_w, col_h = st.sidebar.columns(2)
target_w = col_w.number_input("å¹… (px)", value=600, step=10)
target_h = col_h.number_input("é«˜ã• (px)", value=800, step=10)

st.sidebar.markdown("---")

# 2. æ§‹å›³èª¿æ•´
st.sidebar.subheader("â‘¡ æ§‹å›³èª¿æ•´")
face_ratio = st.sidebar.slider(
    "é¡”ã®å¤§ãã• (Zoom)", 0.2, 0.8, 0.45, 0.01,
    help="å€¤ãŒå¤§ãã„ã»ã©é¡”ãŒã‚¢ãƒƒãƒ—ã«ãªã‚Šã¾ã™ã€‚"
)
eye_level = st.sidebar.slider(
    "ç›®ã®é«˜ã• (ä¸Šä¸‹ä½ç½®)", 0.2, 0.6, 0.40, 0.01,
    help="ä¸Šã‹ã‚‰ã®ä½ç½®(%)ã€‚å€¤ãŒå°ã•ã„ã»ã©é ­ä¸Šã®ä½™ç™½ãŒåºƒããªã‚Šã¾ã™ã€‚"
)

# 3. ä½™ç™½å‡¦ç†
st.sidebar.subheader("â‘¢ ä½™ç™½å‡¦ç†")
st.sidebar.caption("æ‹¡å¤§ãƒ»ç§»å‹•(15%ä»¥å†…)ã§èª¿æ•´ã§ããªã„å ´åˆã®èƒŒæ™¯è‰²")
bg_mode = st.sidebar.radio("èƒŒæ™¯è‰²", ["ç™½", "é»’"], horizontal=True)

st.sidebar.markdown("---")

# 4. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
st.sidebar.subheader("â‘£ å‡ºåŠ›")
if st.session_state['images_data']:
    if st.sidebar.button("ğŸ“¦ ç”»åƒã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", type="primary"):
        zip_buffer = io.BytesIO()
        progress_bar = st.sidebar.progress(0)
        total = len(st.session_state['images_data'])
        
        with zipfile.ZipFile(zip_buffer, "w") as zf:
            for i, (fname, data) in enumerate(st.session_state['images_data'].items()):
                # é«˜ç”»è³ªç”Ÿæˆ
                final_img = create_smart_cropped_image(
                    data['original'], data['face_data'],
                    target_w, target_h, face_ratio, eye_level, bg_mode
                )
                
                img_byte_arr = io.BytesIO()
                final_img.save(img_byte_arr, format='JPEG', quality=95)
                zf.writestr(f"{fname}.jpg", img_byte_arr.getvalue())
                
                progress_bar.progress((i + 1) / total)
        
        st.sidebar.success("å®Œäº†ï¼")
        st.sidebar.download_button(
            label="ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜",
            data=zip_buffer.getvalue(),
            file_name="processed_photos.zip",
            mime="application/zip"
        )

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†™çœŸ è‡ªå‹•ã‚¯ãƒ­ãƒƒãƒ‘ãƒ¼")
st.info("è¨­å®šã‚’å¤‰ãˆã‚‹ã¨ã€è‡ªå‹•çš„ã«ã€Œä½ç½®èª¿æ•´ãƒ»æ‹¡å¤§ãƒ»ä½™ç™½è¿½åŠ ã€ã‚’åˆ¤æ–­ã—ã¦ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ›´æ–°ã—ã¾ã™ã€‚")

uploaded_files = st.file_uploader(
    "ç”»åƒã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", type=['jpg', 'jpeg', 'png', 'pdf'], accept_multiple_files=True
)

if uploaded_files:
    new_count = 0
    for up_file in uploaded_files:
        fname = os.path.splitext(up_file.name)[0]
        if fname not in st.session_state['images_data']:
            img = load_image(up_file)
            if img:
                if img.mode != "RGB": img = img.convert("RGB")
                face_data = analyze_face_coordinates(img)
                st.session_state['images_data'][fname] = {'original': img, 'face_data': face_data}
                new_count += 1
    if new_count > 0:
        st.success(f"{new_count} æšè¿½åŠ ã—ã¾ã—ãŸ")

# --- ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---
if st.session_state['images_data']:
    st.subheader("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å‡ºåŠ›ã‚¤ãƒ¡ãƒ¼ã‚¸)")
    cols = st.columns(4)
    keys = list(st.session_state['images_data'].keys())
    
    for i, key in enumerate(keys):
        data = st.session_state['images_data'][key]
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ (ãƒªã‚µã‚¤ã‚ºæ¸ˆã¿ã®ç”»åƒãŒè¿”ã£ã¦ãã‚‹)
        # é«˜é€ŸåŒ–ã®ãŸã‚ã€å…ƒç”»åƒè‡ªä½“ã‚’å°‘ã—ç¸®å°ã—ã¦ã‹ã‚‰æ¸¡ã—ã¦ã‚‚ã‚ˆã„ãŒã€
        # Streamlit Cloudã®æ€§èƒ½ãªã‚‰ã“ã®ã¾ã¾ã§ã‚‚æ•°æšç¨‹åº¦ãªã‚‰è¨±å®¹ç¯„å›²
        preview_img = create_smart_cropped_image(
            data['original'], data['face_data'],
            target_w, target_h, face_ratio, eye_level, bg_mode
        )
        
        with cols[i % 4]:
            # ç”»åƒã®å½¢ã¯æŒ‡å®šã‚µã‚¤ã‚º(ã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”)ã«çµ±ä¸€ã•ã‚Œã¦è¡¨ç¤ºã•ã‚Œã‚‹
            st.image(preview_img, caption=key, use_column_width=True)

