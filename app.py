import streamlit as st
from PIL import Image, ImageOps
import mediapipe as mp
import numpy as np
import io
import zipfile
import os
import gc  # ãƒ¡ãƒ¢ãƒªæƒé™¤ç”¨
from pdf2image import convert_from_bytes

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(layout="wide", page_title="Profile Photo Cropper")

# --- å®šæ•° ---
# ãƒ¡ãƒ¢ãƒªå¯¾ç­–: ä½œæ¥­ç”¨ç”»åƒã®æœ€å¤§ã‚µã‚¤ã‚º(é•·è¾ºpx)
# å‡ºåŠ›ã‚µã‚¤ã‚ºãŒ800pxç¨‹åº¦ãªã‚‰ã€2000pxã‚ã‚Œã°ã‚ºãƒ¼ãƒ ã—ã¦ã‚‚ååˆ†é«˜ç”»è³ªã‚’ç¶­æŒã§ãã€ã‹ã¤ãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„ã§ãã‚‹
MAX_WORKING_SIZE = 2000 

# --- é–¢æ•°å®šç¾© ---

def resize_if_huge(image):
    """ç”»åƒãŒå·¨å¤§ã™ãã‚‹å ´åˆã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ã¦ãƒªã‚µã‚¤ã‚ºã™ã‚‹"""
    w, h = image.size
    max_dim = max(w, h)
    if max_dim > MAX_WORKING_SIZE:
        scale = MAX_WORKING_SIZE / max_dim
        new_w = int(w * scale)
        new_h = int(h * scale)
        return image.resize((new_w, new_h), Image.Resampling.LANCZOS)
    return image

def load_image(uploaded_file):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿PIL Imageã«å¤‰æ› (ãƒ¡ãƒ¢ãƒªå¯¾ç­–è¾¼ã¿)"""
    try:
        image = None
        if uploaded_file.type == "application/pdf":
            # PDFã¯300dpiã§å¤‰æ›ã—ã¦é¡”èªè­˜ç²¾åº¦ã‚’ç¢ºä¿
            images = convert_from_bytes(uploaded_file.getvalue(), dpi=300, fmt='jpeg')
            if images:
                image = images[0]
        else:
            image = Image.open(uploaded_file)
            image = ImageOps.exif_transpose(image) # å›è»¢è£œæ­£
        
        if image:
            # ã“ã“ã§å·¨å¤§ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã¦ãƒ¡ãƒ¢ãƒªçˆ†ç™ºã‚’é˜²ã
            image = resize_if_huge(image)
            return image
        return None
    except Exception as e:
        st.error(f"Error loading {uploaded_file.name}: {e}")
        return None

def analyze_face_coordinates(image, confidence_threshold):
    """æŒ‡å®šã•ã‚ŒãŸæ„Ÿåº¦(confidence)ã§é¡”æ¤œå‡ºã‚’è¡Œã†"""
    mp_face_detection = mp.solutions.face_detection
    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=confidence_threshold) as face_detection:
        img_np = np.array(image.convert('RGB'))
        results = face_detection.process(img_np)
        
        # ãƒ¡ãƒ¢ãƒªé–‹æ”¾
        del img_np
        
        if not results.detections:
            return None

        detection = results.detections[0]
        bbox = detection.location_data.relative_bounding_box
        kps = detection.location_data.relative_keypoints
        
        right_eye = kps[0]
        left_eye = kps[1]
        eye_center_x = (right_eye.x + left_eye.x) / 2
        eye_center_y = (right_eye.y + left_eye.y) / 2
        
        return {
            'face_h': bbox.height,
            'face_cx': bbox.xmin + bbox.width / 2,
            'face_cy': bbox.ymin + bbox.height / 2,
            'eye_cy': eye_center_y
        }

def create_smart_cropped_image(original_img, face_data, target_w, target_h, face_ratio, eye_level, bg_mode):
    """æœ€çµ‚ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ï¼ˆ15%ãƒ«ãƒ¼ãƒ« & ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†è¾¼ã¿ï¼‰"""
    img_w, img_h = original_img.size
    
    # 1. ç†æƒ³ã®åˆ‡ã‚ŠæŠœãæ 
    if face_data:
        face_h_px = face_data['face_h'] * img_h
        crop_h = face_h_px / face_ratio
        eye_y_px = face_data['eye_cy'] * img_h
        crop_top = eye_y_px - (crop_h * eye_level)
        crop_cy = crop_top + (crop_h / 2)
        crop_cx = face_data['face_cx'] * img_w
    else:
        crop_h = img_h * 0.8
        crop_cx, crop_cy = img_w / 2, img_h / 2

    target_aspect = target_w / target_h
    crop_w = crop_h * target_aspect
    
    x1, y1, x2, y2 = crop_cx - crop_w/2, crop_cy - crop_h/2, crop_cx + crop_w/2, crop_cy + crop_h/2
    
    # 2. è‡ªå‹•èª¿æ•´ (15%ãƒ«ãƒ¼ãƒ«)
    overflow_left = max(0, -x1)
    overflow_right = max(0, x2 - img_w)
    overflow_top = max(0, -y1)
    overflow_bottom = max(0, y2 - img_h)
    has_overflow = (overflow_left + overflow_right + overflow_top + overflow_bottom) > 0
    
    final_x1, final_y1, final_x2, final_y2 = x1, y1, x2, y2
    needs_padding = False
    
    if has_overflow:
        if crop_w <= img_w:
            if final_x1 < 0:
                offset = -final_x1
                final_x1 += offset
                final_x2 += offset
            elif final_x2 > img_w:
                offset = final_x2 - img_w
                final_x1 -= offset
                final_x2 -= offset
        if crop_h <= img_h:
            if final_y1 < 0:
                offset = -final_y1
                final_y1 += offset
                final_y2 += offset
            elif final_y2 > img_h:
                offset = final_y2 - img_h
                final_y1 -= offset
                final_y2 -= offset

        scale_w = img_w / crop_w if crop_w > img_w else 1.0
        scale_h = img_h / crop_h if crop_h > img_h else 1.0
        min_scale = min(scale_w, scale_h)
        ALLOWED_SHRINK_LIMIT = 1.0 / 1.15
        
        if min_scale >= ALLOWED_SHRINK_LIMIT:
            new_crop_w = crop_w * min_scale
            new_crop_h = crop_h * min_scale
            center_x = (final_x1 + final_x2) / 2
            center_y = (final_y1 + final_y2) / 2
            center_x = max(new_crop_w/2, min(img_w - new_crop_w/2, center_x))
            center_y = max(new_crop_h/2, min(img_h - new_crop_h/2, center_y))
            final_x1, final_y1, final_x2, final_y2 = center_x - new_crop_w/2, center_y - new_crop_h/2, center_x + new_crop_w/2, center_y + new_crop_h/2
        else:
            final_x1, final_y1, final_x2, final_y2 = x1, y1, x2, y2
            needs_padding = True
    
    # 3. ç”Ÿæˆ
    if not needs_padding:
        cx1, cy1, cx2, cy2 = max(0, final_x1), max(0, final_y1), min(img_w, final_x2), min(img_h, final_y2)
        cropped = original_img.crop((cx1, cy1, cx2, cy2))
        return cropped.resize((target_w, target_h), Image.Resampling.LANCZOS)
    else:
        bg_color = (255, 255, 255) if bg_mode == "ç™½" else (0, 0, 0)
        src_aspect = img_w / img_h
        if src_aspect > target_aspect:
            resize_w, resize_h = target_w, int(target_w / src_aspect)
        else:
            resize_w, resize_h = int(target_h * src_aspect), target_h
        resized_src = original_img.resize((resize_w, resize_h), Image.Resampling.LANCZOS)
        new_img = Image.new("RGB", (target_w, target_h), bg_color)
        new_img.paste(resized_src, ((target_w - resize_w)//2, (target_h - resize_h)//2))
        return new_img

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
if 'images_data' not in st.session_state:
    st.session_state['images_data'] = {} 
if 'last_detection_confidence' not in st.session_state:
    st.session_state['last_detection_confidence'] = 0.5

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼æ§‹æˆ ---
st.sidebar.title("è¨­å®š")

# 0. ãƒ¡ãƒ¢ãƒªé–‹æ”¾ãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ", help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã‚’å…¨ã¦ã‚¯ãƒªã‚¢ã—ã¾ã™"):
    st.session_state['images_data'] = {}
    gc.collect() # å¼·åˆ¶ãƒ¡ãƒ¢ãƒªæƒé™¤
    st.rerun()

st.sidebar.markdown("---")

# 1. é¡”èªè­˜è¨­å®š
st.sidebar.subheader("â‘  é¡”èªè­˜ã®ç²¾åº¦")
confidence_val = st.sidebar.slider(
    "æ¤œå‡ºæ„Ÿåº¦ (ä½ã„ã»ã©æ¤œå‡ºã—ã‚„ã™ã„)", 
    0.1, 0.9, 0.5, 0.05,
    help="é¡”ãŒèªè­˜ã•ã‚Œãªã„å ´åˆã¯å€¤ã‚’ä¸‹ã’ã¦ã¿ã¦ãã ã•ã„ã€‚"
)

# æ„Ÿåº¦ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆ
if abs(confidence_val - st.session_state['last_detection_confidence']) > 0.001:
    if st.session_state['images_data']:
        with st.spinner("æ–°ã—ã„æ„Ÿåº¦ã§é¡”ã‚’å†æ¤œå‡ºä¸­..."):
            for key in st.session_state['images_data']:
                img = st.session_state['images_data'][key]['original']
                new_face_data = analyze_face_coordinates(img, confidence_val)
                st.session_state['images_data'][key]['face_data'] = new_face_data
            gc.collect() # å‡¦ç†å¾Œã«æƒé™¤
    st.session_state['last_detection_confidence'] = confidence_val
    st.rerun()

st.sidebar.markdown("---")

# 2. å‡ºåŠ›ã‚µã‚¤ã‚º
st.sidebar.subheader("â‘¡ å‡ºåŠ›ã‚µã‚¤ã‚º")
col_w, col_h = st.sidebar.columns(2)
target_w = col_w.number_input("å¹… (px)", value=600, step=10)
target_h = col_h.number_input("é«˜ã• (px)", value=800, step=10)

# 3. æ§‹å›³èª¿æ•´
st.sidebar.subheader("â‘¢ æ§‹å›³èª¿æ•´")
face_ratio = st.sidebar.slider("é¡”ã®å¤§ãã• (Zoom)", 0.2, 0.8, 0.45, 0.01)
eye_level = st.sidebar.slider("ç›®ã®é«˜ã• (ä¸Šä¸‹ä½ç½®)", 0.2, 0.6, 0.40, 0.01)

# 4. ä½™ç™½å‡¦ç†
st.sidebar.subheader("â‘£ ä½™ç™½å‡¦ç†")
bg_mode = st.sidebar.radio("èƒŒæ™¯è‰²", ["ç™½", "é»’"], horizontal=True)

st.sidebar.markdown("---")

# 5. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³é…ç½®ç”¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
download_placeholder = st.sidebar.empty()


# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†™çœŸ è‡ªå‹•ã‚¯ãƒ­ãƒƒãƒ‘ãƒ¼")

uploaded_files = st.file_uploader(
    "ç”»åƒã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", type=['jpg', 'jpeg', 'png', 'pdf'], accept_multiple_files=True
)

if uploaded_files:
    new_count = 0
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤ºï¼ˆå¤§é‡ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ãƒ•ãƒªãƒ¼ã‚ºé˜²æ­¢æ„Ÿï¼‰
    progress_text = "ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­..."
    my_bar = st.progress(0, text=progress_text)
    
    total_files = len(uploaded_files)
    
    for i, up_file in enumerate(uploaded_files):
        fname = os.path.splitext(up_file.name)[0]
        if fname not in st.session_state['images_data']:
            img = load_image(up_file)
            if img:
                if img.mode != "RGB": img = img.convert("RGB")
                face_data = analyze_face_coordinates(img, confidence_val)
                st.session_state['images_data'][fname] = {'original': img, 'face_data': face_data}
                new_count += 1
        
        # é€²æ—æ›´æ–°
        my_bar.progress((i + 1) / total_files, text=f"èª­ã¿è¾¼ã¿ä¸­... {i+1}/{total_files}")
    
    my_bar.empty()
    gc.collect() # èª­ã¿è¾¼ã¿å®Œäº†å¾Œã«ä¸€å›æƒé™¤
    
    if new_count > 0:
        st.success(f"{new_count} æšè¿½åŠ ã—ã¾ã—ãŸ")

# --- ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º ---
if st.session_state['images_data']:
    st.subheader("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å‡ºåŠ›ã‚¤ãƒ¡ãƒ¼ã‚¸)")
    cols = st.columns(4)
    keys = list(st.session_state['images_data'].keys())
    
    for i, key in enumerate(keys):
        data = st.session_state['images_data'][key]
        preview_img = create_smart_cropped_image(
            data['original'], data['face_data'],
            target_w, target_h, face_ratio, eye_level, bg_mode
        )
        with cols[i % 4]:
            st.image(preview_img, caption=key, use_column_width=True)

    # --- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ ---
    with download_placeholder.container():
        st.subheader("â‘¤ å‡ºåŠ›")
        if st.button("ğŸ“¦ ç”»åƒã‚’ä½œæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", type="primary"):
            zip_buffer = io.BytesIO()
            progress_bar = st.progress(0)
            status_text = st.empty()
            total = len(st.session_state['images_data'])
            
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for i, (fname, data) in enumerate(st.session_state['images_data'].items()):
                    status_text.text(f"å‡¦ç†ä¸­: {fname}...")
                    final_img = create_smart_cropped_image(
                        data['original'], data['face_data'],
                        target_w, target_h, face_ratio, eye_level, bg_mode
                    )
                    img_byte_arr = io.BytesIO()
                    final_img.save(img_byte_arr, format='JPEG', quality=95)
                    zf.writestr(f"{fname}.jpg", img_byte_arr.getvalue())
                    progress_bar.progress((i + 1) / total)
                    
                    # 1æšã”ã¨ã«ãƒ¡ãƒ¢ãƒªæƒé™¤
                    del final_img
                    del img_byte_arr
                    if i % 5 == 0: gc.collect()
            
            progress_bar.empty()
            status_text.empty()
            gc.collect()
            
            st.success("ä½œæˆå®Œäº†ï¼ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ä¿å­˜ã—ã¦ãã ã•ã„")
            st.download_button(
                label="ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜",
                data=zip_buffer.getvalue(),
                file_name="processed_photos.zip",
                mime="application/zip"
            )
else:
    download_placeholder.info("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
